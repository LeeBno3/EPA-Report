{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f93814b",
   "metadata": {},
   "source": [
    "# Code for Retirement Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92b507",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "* [1. Importing Libraries](#1.-Importing-Libraries)\n",
    "\n",
    "* [2. Data Pre-processing](#2.-Data-Pre-processing)\n",
    "> * [2.1. Data loading](#2.1.-Data-loading)\n",
    "> * [2.2. Intial exploration of data](#2.2.-Intial-exploration-of-data)\n",
    "> * [2.3. Data Cleaning, Wrangling, Feature Reduction & Feature Engineering](#2.3.-Data-Cleaning,-Wrangling,-Feature-Reduction-&-Feature-Engineering)\n",
    ">> * [2.3.1. Person Number: Handling missing values](#2.3.1.-Person-Number:-Handling-missing-values)\n",
    ">> * [2.3.2. Reviewing and transforming values in columns](#2.3.2.-Reviewing-and-transforming-values-in-columns)\n",
    ">> * [2.3.3. Renaming features](#2.3.3.-Renaming-features)\n",
    ">> * [2.3.4. Dropping features](#2.3.4.-Dropping-features)\n",
    ">> * [2.3.5. Feature Engineering & Creation](#2.3.5.-Feature-Engineering-&-Creation)\n",
    ">> * [2.3.6. Dealing with the period of the Pandemic](#2.3.6.-Dealing-with-the-period-of-the-Pandemic)\n",
    "> * [2.4. Visualising features](#2.4.-Visualising-features)\n",
    ">> * [2.4.1. Bar plots](#2.4.1.-Bar-plots)\n",
    ">> * [2.4.2. Histograms](#2.4.2.-Histograms)\n",
    "> * [2.5. Feature Relationship](#2.5.-Feature-Relationship)\n",
    ">> * [2.5.1. Calculation of Bivariate Stats](#2.5.1.-Calculation-of-Bivariate-Stats)\n",
    ">> * [2.5.2. Pairplots](#2.5.2.-Pairplots)\n",
    ">> * [2.5.3. Heatmap](#2.5.3.-Heatmap)\n",
    "\n",
    "* [3. Modelling Preparation](#3.-Modelling-Preparation)\n",
    "> * [3.1. Final feature changes](#3.1.-Final-feature-changes)\n",
    "> * [3.2. One Hot Encoding](#3.2.-One-Hot-Encoding)\n",
    "> * [3.3. Normalisation](#3.3.-Normalisation)\n",
    "> * [3.4. Training - Testing split](#3.4.-Training---Testing-split)\n",
    "\n",
    "* [4. Classification Models](#4.-Classification-Models)\n",
    "> * [4.1. Random Forest](#4.1.-Random-Forest)\n",
    ">> * [4.1.1. Random Forest - First Run](#4.1.1.-Random-Forest---First-Run)\n",
    ">> * [4.1.2. Random Forest - Tuning Hyperparameters](#4.1.2.-Random-Forest---Tuning-Hyperparameters)\n",
    "> * [4.2. Support Vector Machines (SVM)](#4.2.-Support-Vector-Machines-(SVM))\n",
    ">> * [4.2.1. SVM - First Run](#4.2.1.-SVM---First-Run)\n",
    ">> * [4.2.2. SVM - Tuning hyperparameters](#4.2.2.-SVM---Tuning-hyperparameters)\n",
    "> * [4.3. Logistic Regression](#4.3.-Logistic-Regression)\n",
    ">> * [4.3.1. Logistic Regression - First Run](#4.3.1.-Logistic-Regression---First-Run)\n",
    ">> * [4.3.2. Logistic Regression - Tuning hyperparameters](#4.3.2.-Logistic-Regression---Tuning-hyperparameters)\n",
    "> * [4.4. K-Nearest Neighbour (KNN)](#4.4.-K-Nearest-Neighbour-(KNN))\n",
    ">> * [4.4.1. KNN - First Run](#4.4.1.-KNN---First-Run)\n",
    ">> * [4.4.2. KNN - Tuning hyperparameters](#4.4.2.-KNN---Tuning-hyperparameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d31ac",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4301ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d15552",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5db57f",
   "metadata": {},
   "source": [
    "### 2.1. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0a5f4",
   "metadata": {},
   "source": [
    "#### Importing the data files\n",
    "\n",
    "This is the data that I have exported from our internal HR System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pension         = pd.read_csv(\"HMLR_121 Pension Scheme - anonymised.csv\")\n",
    "data_additional_info = pd.read_csv(\"Retirement Modelling Test report - anonymised.csv\")\n",
    "data_leavers         = pd.read_csv(\"HMLR_026 Leavers Report - April 2018 - March 2023 - anonymised.csv\")\n",
    "\n",
    "pension_shape         = str(data_pension.shape)\n",
    "additional_info_shape = str(data_additional_info.shape)\n",
    "leavers_shape         = str(data_leavers.shape)\n",
    "\n",
    "print(\"The size of the pension data is: \" + pension_shape)\n",
    "print(\"The size of the additional information is: \" + additional_info_shape)\n",
    "print(\"The size of the leavers data is: \" + leavers_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e932523",
   "metadata": {},
   "source": [
    "The head method is used to quickly review each of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04922b68",
   "metadata": {},
   "source": [
    "##### Pension Scheme Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pension.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92643979",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pension.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754356b4",
   "metadata": {},
   "source": [
    "##### Personal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4beb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_additional_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098224c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_additional_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b7b92",
   "metadata": {},
   "source": [
    "##### Leavers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_leavers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_leavers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82a30f",
   "metadata": {},
   "source": [
    "#### Combining all imported dataframes\n",
    "\n",
    "The code below is to merge the imported dataframes using the uinque Person Number (Employee ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7743cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge_stage_1 = pd.merge(data_leavers, data_pension, on='Person Number', how='left')\n",
    "data_total_merge   = pd.merge(data_merge_stage_1, data_additional_info, on='Person Number', how='left')\n",
    "\n",
    "# reviewing the resulting dataframe\n",
    "\n",
    "data_total_merge.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to review the shape of the new dataframe\n",
    "\n",
    "combined_shape = str(data_total_merge.shape)\n",
    "\n",
    "print(\"The combined size of the data extracts is: \" + combined_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa5a4e",
   "metadata": {},
   "source": [
    "### 2.2. Intial exploration of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bf365",
   "metadata": {},
   "source": [
    "The following function below is to assist with collecting various univariate stats and loading them into a new dataframe to assist with understanding the dataset and start the process of cleaning and transforming the data before delving into more detailed data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_stats(df):\n",
    "    import pandas as pd\n",
    "    output_df = pd.DataFrame(columns=['Count','Missing','Unique','Dtype','Numeric','Mode','Mean','Min','25%','Median',\n",
    "                                      '75%','Max','Std','Skew','Kurtosis'])\n",
    "    \n",
    "    for col in df:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            output_df.loc[col] = [df[col].count(), df[col].isnull().sum(), df[col].nunique(), df[col].dtype,\n",
    "                                  pd.api.types.is_numeric_dtype(df[col]), df[col].mode().values[0], df[col].mean(),\n",
    "                                  df[col].min(), df[col].quantile(0.25), df[col].median(), df[col].quantile(0.75),\n",
    "                                  df[col].max(), df[col].std(), df[col].skew(), df[col].kurt()]\n",
    "        \n",
    "        else:\n",
    "            output_df.loc[col] = [df[col].count(), df[col].isnull().sum(), df[col].nunique(), df[col].dtype,\n",
    "                                  pd.api.types.is_numeric_dtype(df[col]), df[col].mode().values[0], '-','-','-','-',\n",
    "                                  '-','-','-','-','-']\n",
    "            \n",
    "    return output_df.sort_values(by=['Numeric', 'Skew', 'Unique'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_stats(data_total_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2d794",
   "metadata": {},
   "source": [
    "### 2.3. Data Cleaning, Wrangling, Feature Reduction & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753f1fa",
   "metadata": {},
   "source": [
    "After an intial review of the univariate stats there are a number of Cleaning and Wrangling steps that are required before exploring the data in more detail. These steps include:\n",
    "\n",
    "- Calculating Age.\n",
    "- Calculating Length of Service (LOS) - both Civil Service (CS) and His Majesty's Land Registry (HMLR).\n",
    "- Reviewing duplicate entries.\n",
    "- Dropping any features that are not required or may add bias to the data when running through the machine learning algorithms.\n",
    "- Transforming categorical features into numeric fields where they are a binary option.\n",
    "- Data transformation of values in columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84077056",
   "metadata": {},
   "source": [
    "#### 2.3.1. Person Number: Handling missing values\n",
    "\n",
    "##### Duplicate values\n",
    "\n",
    "Using the univariate DataFrame we can see that there is a duplicate row of data. My knowledge of the organisations HR database I know that during migration there were some issues with some employee assignment records and these duplicates are expected and we can delete one of the rows as it is due to a data migration error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc90166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the duplicate exists as the Unique value is not the same as the Count value.\n",
    "\n",
    "univariate_stats(data_total_merge).loc['Person Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove the second instance of the duplicated row of data.\n",
    "\n",
    "data_total_merge = data_total_merge.drop_duplicates(subset=['Person Number'], keep='first')\n",
    "\n",
    "# Showing the results of dropping the duplicate.\n",
    "\n",
    "univariate_stats(data_total_merge).loc['Person Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3af71",
   "metadata": {},
   "source": [
    "The univariate statistics show that the `Usage Code for Person : HMLR and CS General Entry Dates : CS Current Entry Date` has a missing value. Given that this is a date value it is only a single missing value I have decided to drop this row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming that there is a missing value in this feature\n",
    "\n",
    "univariate_stats(data_total_merge).loc['Usage Code for Person : HMLR and CS General Entry Dates : CS Current Entry Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing value\n",
    "\n",
    "data_total_merge.dropna(subset=['Usage Code for Person : HMLR and CS General Entry Dates : CS Current Entry Date'],\n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the result of dropping the missing value\n",
    "\n",
    "univariate_stats(data_total_merge).loc['Usage Code for Person : HMLR and CS General Entry Dates : CS Current Entry Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee64ac",
   "metadata": {},
   "source": [
    "#### 2.3.2. Reviewing and transforming values in columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358430bb",
   "metadata": {},
   "source": [
    "`Assignment Category`\n",
    "\n",
    "The Assignment Category field holds a number of different entries related to staff. There are two entries:\n",
    "`Partial retirement` and `Partial retirement PartTime` \n",
    "that are needed and the rest are not relevant. \n",
    "\n",
    "I will create a field to show a binary result as to whether an employee is partially retired or not and then the assignment category field will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the unique values in the column\n",
    "\n",
    "print(data_total_merge['Assignment Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to transform the data into a binary output of Partially Retired or not into a new column.\n",
    "\n",
    "data_total_merge.loc[(data_total_merge['Assignment Category'] == 'Partial retirement') | \n",
    "                     (data_total_merge['Assignment Category'] == 'Partial retirement PartTime'), 'Partial_Retirement'] = 1  \n",
    "\n",
    "data_total_merge.loc[(data_total_merge['Assignment Category'] != 'Partial retirement') & \n",
    "                     (data_total_merge['Assignment Category'] != 'Partial retirement PartTime'), 'Partial_Retirement'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7d474",
   "metadata": {},
   "source": [
    "`Element Name`\n",
    "\n",
    "The Element Name lists the Pension Scheme that employees are a part of but there are a number of different entries that are related to the Schemes. The following code will clean the data to reduce the list to the specific Pension Schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the unique values in the column\n",
    "\n",
    "print(data_total_merge['Element Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66271413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Element Name column with Pension data as Alpha, Classic, Classic Plus and the rest of the Pension Schemes.\n",
    "\n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'Classic Civil Servant Pension') | (data_total_merge['Element Name'] == 'Classic CS Added'), 'Pension Scheme'] = 'Classic' \n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'Premium Civil Servant Pension') | (data_total_merge['Element Name'] == 'Premium CS Added'), 'Pension Scheme'] = 'Premium'\n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'Alpha Pension Scheme') | (data_total_merge['Element Name'] == 'Alpha EPA 1 2015'), 'Pension Scheme'] = 'Alpha' \n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'Add Pension Member (Alpha) 2015') | (data_total_merge['Element Name'] == 'Additional Pension (Alpha) 2015'), 'Pension Scheme'] = 'Alpha'\n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'Classic Plus Civil Servant Pension') | (data_total_merge['Element Name'] == 'Classic Plus CS Added'), 'Pension Scheme'] = 'Classic Plus'\n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'Nuvos Civil Servant Pension'), 'Pension Scheme'] = 'Nuvos' \n",
    "data_total_merge.loc[(data_total_merge['Element Name'] == 'L&G Defined Contribution Pension'), 'Pension Scheme'] = 'L&G'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a006f2",
   "metadata": {},
   "source": [
    "From reviewing the unique value output there are rows of data that do not have a `Pension Scheme`. The decision after reviewing this data is to replace the `nan` values and replace them with an `Unknown` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cce7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to handle the missing values in the new column\n",
    "\n",
    "data_total_merge['Pension Scheme'] = data_total_merge['Pension Scheme'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1762657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values in the new column\n",
    "\n",
    "print(data_total_merge['Pension Scheme'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085146ca",
   "metadata": {},
   "source": [
    "#### 2.3.3. Renaming features\n",
    "\n",
    "Some features need to be renamed to help describe what teh column is for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fe6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming of Attributes\n",
    "\n",
    "data_total_merge.rename(columns = {'Usage Code for Person : HMLR and CS General Entry Dates : CS Current Entry Date':\n",
    "                                   'Civil Service Entry Date'}, inplace = True)\n",
    "\n",
    "data_total_merge.rename(columns = {'Action Name':'Leaving Reason'}, inplace = True)\n",
    "\n",
    "data_total_merge.rename(columns = {'Full/Part Time':'Fulltime=1/Part-time=0'}, inplace = True)\n",
    "\n",
    "data_total_merge.rename(columns = {'Termination Date_x':'Leaving Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee72bb",
   "metadata": {},
   "source": [
    "#### 2.3.4. Dropping features\n",
    "\n",
    "There are a number of features that are not required. This is for different reasons such as:\n",
    "\n",
    "- Not enough date: `Pension opt out date`\n",
    "- Duplicated features from merging dataframes: `System Person Type_x`, `Termination Date_y`\n",
    "- Required for steps after modelling: `Department`, `Cost Centre`\n",
    "- Other features provide the same data: `Full-Time Equivalent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge = data_total_merge.drop(['System Person Type_x','Employee Type',\n",
    "                                          'Full-Time Equivalent','Payroll Status',\n",
    "                                          'Action Reason','Effective Start Date',\n",
    "                                          'Effective End Date','Input Value Name',\n",
    "                                          'Pension opt out date','Termination Date_y',\n",
    "                                          'System Person Type_y','Cost Centre',\n",
    "                                          'Department', 'Assignment Category',\n",
    "                                          'Element Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c226f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_stats(data_total_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcccfee",
   "metadata": {},
   "source": [
    "#### 2.3.5. Feature Engineering & Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f8a31",
   "metadata": {},
   "source": [
    "There are a number of attributes that we need to calculate from the date fields such as:\n",
    "- `Age (Years)`: Age of employee when leaving\n",
    "- `CS LOS (Years)`: Civil Service Length of Service\n",
    "- `HMLR LOS (Years)`: HM Land Registry Length of Service\n",
    "\n",
    "To do this I have calculated the difference in the relevant months before converting this to years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age at point of leaving in months\n",
    "\n",
    "data_total_merge['Leaving Date'] = pd.to_datetime(data_total_merge['Leaving Date'],dayfirst=True)\n",
    "data_total_merge['Date of Birth'] = pd.to_datetime(data_total_merge['Date of Birth'],dayfirst=True)\n",
    "\n",
    "data_total_merge['Age (Months)'] = (data_total_merge['Leaving Date'] - data_total_merge['Date of Birth']).astype('<m8[M]')\n",
    "\n",
    "# Calculate CS LOS in months\n",
    "\n",
    "data_total_merge['Leaving Date'] = pd.to_datetime(data_total_merge['Leaving Date'],dayfirst=True)\n",
    "data_total_merge['Civil Service Entry Date'] = pd.to_datetime(data_total_merge['Civil Service Entry Date'],dayfirst=True)\n",
    "\n",
    "data_total_merge['CS LOS (Months)'] = (data_total_merge['Leaving Date'] - data_total_merge['Civil Service Entry Date']).astype('<m8[M]')\n",
    "\n",
    "# Calculate HMLR LOS in months\n",
    "\n",
    "data_total_merge['Leaving Date'] = pd.to_datetime(data_total_merge['Leaving Date'],dayfirst=True)\n",
    "data_total_merge['Enterprise Hire Date'] = pd.to_datetime(data_total_merge['Enterprise Hire Date'],dayfirst=True)\n",
    "\n",
    "data_total_merge['HMLR LOS (Months)'] = (data_total_merge['Leaving Date'] - data_total_merge['Enterprise Hire Date']).astype('<m8[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date calculations from months to years\n",
    "\n",
    "data_total_merge['Age (years)'] = round((data_total_merge['Age (Months)'] / 12),2)\n",
    "data_total_merge['CS LOS (years)'] = round((data_total_merge['CS LOS (Months)'] / 12),2)\n",
    "data_total_merge['HMLR LOS (years)'] = round((data_total_merge['HMLR LOS (Months)'] / 12),2)\n",
    "\n",
    "data_total_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c564a1",
   "metadata": {},
   "source": [
    "#### 2.3.6. Dealing with the period of the Pandemic\n",
    "\n",
    "To try to take into account the impact that the Pandemic had on the behaviour of staff I will create a feature to categorise the date that someone left HM Land Registry as being Pre, During or Post Pandemic.\n",
    "\n",
    "The dates selected for the During Pandemic Period starts at the point that the first lockdown started: `01 March 2020`, until `31 March 2022` when the last restrictions were lifted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assign the data row a Pre, during or Post Pandemic category.\n",
    "\n",
    "def calculate_result(date):\n",
    "    # Convert the date to a datetime object\n",
    "    date = pd.to_datetime(date)\n",
    "\n",
    "    if date < pd.to_datetime('2020-03-01'):\n",
    "        return \"Pre-Pandemic\"\n",
    "    elif pd.to_datetime('2020-03-01') <= date <= pd.to_datetime('2022-03-31'):\n",
    "        return \"During-Pandemic\"\n",
    "    else:\n",
    "        return \"Post-Pandemic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084903c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Pandemic feature\n",
    "\n",
    "data_total_merge['Pandemic'] = data_total_merge['Leaving Date'].apply(calculate_result)\n",
    "\n",
    "data_total_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586eea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the features that are no longer required after the creation of the new features\n",
    "\n",
    "data_total_merge = data_total_merge.drop(['Leaving Date','Enterprise Hire Date','Date of Birth','Civil Service Entry Date',\n",
    "                                          'Age (Months)','CS LOS (Months)','HMLR LOS (Months)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge = data_total_merge.astype({'Person Number': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_stats(data_total_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864cc3e",
   "metadata": {},
   "source": [
    "### 2.4. Visualising features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988d271",
   "metadata": {},
   "source": [
    "#### 2.4.1. Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "# Creating counts and columns\n",
    "column1 = data_total_merge['Location']\n",
    "counts1 = data_total_merge['Location'].value_counts()\n",
    "\n",
    "column2 = data_total_merge['Grade']\n",
    "counts2 = data_total_merge['Grade'].value_counts()\n",
    "\n",
    "column3 = data_total_merge['Directorate']\n",
    "counts3 = data_total_merge['Directorate'].value_counts()\n",
    "\n",
    "column4 = data_total_merge['Pension Scheme']\n",
    "counts4 = data_total_merge['Pension Scheme'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(20, 15))\n",
    "\n",
    "# Create a bar plot for Location in the first subplot\n",
    "sns.countplot(x=column1, data=data_total_merge, ax=axes[0])\n",
    "axes[0].set_title('Bar plot for Location')\n",
    "\n",
    "sns.countplot(x=column2, data=data_total_merge, ax=axes[1])\n",
    "axes[1].set_title('Bar plot for Grade')\n",
    "\n",
    "sns.countplot(x=column3, data=data_total_merge, ax=axes[2])\n",
    "axes[2].set_title('Bar plot for Directorate')\n",
    "\n",
    "sns.countplot(x=column4, data=data_total_merge, ax=axes[3])\n",
    "axes[3].set_title('Bar plot for Pension Scheme')\n",
    "\n",
    "# Adjust layout and show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "# Creating counts and columns\n",
    "column5 = data_total_merge['Pandemic']\n",
    "counts5 = data_total_merge['Pandemic'].value_counts()\n",
    "\n",
    "column6 = data_total_merge['Fulltime=1/Part-time=0']\n",
    "counts6 = data_total_merge['Fulltime=1/Part-time=0'].value_counts()\n",
    "\n",
    "column7 = data_total_merge['Person Gender']\n",
    "counts7 = data_total_merge['Person Gender'].value_counts()\n",
    "\n",
    "column8 = data_total_merge['Partial_Retirement']\n",
    "counts8 = data_total_merge['Partial_Retirement'].value_counts()\n",
    "\n",
    "column9 = data_total_merge['Leaving Reason']\n",
    "counts9 = data_total_merge['Leaving Reason'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(20, 15))\n",
    "\n",
    "# Create a bar plot for Location in the first subplot\n",
    "sns.countplot(x=column5, data=data_total_merge, ax=axes[0])\n",
    "axes[0].set_title('Bar plot for Pandemic')\n",
    "\n",
    "sns.countplot(x=column9, data=data_total_merge, ax=axes[1])\n",
    "axes[1].set_title('Bar plot for Leaving Reason')\n",
    "\n",
    "sns.countplot(x=column6, data=data_total_merge, ax=axes[2])\n",
    "axes[2].set_title('Bar plot for Working Pattern')\n",
    "\n",
    "sns.countplot(x=column7, data=data_total_merge, ax=axes[3])\n",
    "axes[3].set_title('Bar plot for Gender')\n",
    "\n",
    "sns.countplot(x=column8, data=data_total_merge, ax=axes[4])\n",
    "axes[4].set_title('Bar plot for Partial Retirement')\n",
    "\n",
    "# Adjust layout and show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f776b",
   "metadata": {},
   "source": [
    "#### 2.4.2. Count plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ea95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(20, 15))\n",
    "\n",
    "# Create data groups for plotting\n",
    "data_total_merge[\"Age_Group\"] = pd.cut(data_total_merge[\"Age (years)\"], bins=[0, 20, 30, 40, 50, 55, 60, 65, 70, 100], \n",
    "                                       labels=[\"<20\", \"20-29\", \"30-39\", \"40-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70+\"])\n",
    "\n",
    "data_total_merge[\"HMLR LOS\"] = pd.cut(data_total_merge[\"HMLR LOS (years)\"], bins=[0, 1, 3, 5, 10, 15, 20, 25, 30, 35, 40, 100], \n",
    "                                      labels=[\"<1\", \"1-3\", \"4-5\", \"6-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-35\", \"36-40\", \">40\"])\n",
    "\n",
    "data_total_merge[\"CS LOS\"] = pd.cut(data_total_merge[\"CS LOS (years)\"], bins=[0, 1, 3, 5, 10, 15, 20, 25, 30, 35, 40, 100], \n",
    "                                      labels=[\"<1\", \"1-3\", \"4-5\", \"6-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-35\", \"36-40\", \">40\"])\n",
    "\n",
    "# Using countplot for displaying counts of each group:\n",
    "sns.countplot(x=\"Age_Group\", data=data_total_merge, ax=axes[0])\n",
    "axes[0].set_title(\"Age Group Distribution\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "sns.countplot(x=\"HMLR LOS\", data=data_total_merge, ax=axes[1])\n",
    "axes[1].set_title(\"HMLR Length of Service Distribution\")\n",
    "plt.xlabel(\"HMLR LOS\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "sns.countplot(x=\"CS LOS\", data=data_total_merge, ax=axes[2])\n",
    "axes[2].set_title(\"Civil Service Length of Service Distribution\")\n",
    "plt.xlabel(\"CS LOS\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "#sns.barplot(data=data_total_merge, x='CS LOS (years)', bins=10, ax=axes[2])\n",
    "#axes[2].set_title('Civil Service - Length of Service (years)')\n",
    "\n",
    "# Adjust layout and show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516eb96",
   "metadata": {},
   "source": [
    "Showing these visuals filtered by Leaving Reason = Retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data_total_merge[data_total_merge['Leaving Reason'] == 'Retirement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb84753",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(20, 15))\n",
    "\n",
    "# Create data groups for plotting\n",
    "filtered_data[\"Age_Group\"] = pd.cut(filtered_data[\"Age (years)\"], bins=[0, 20, 30, 40, 50, 55, 60, 65, 70, 100], \n",
    "                                       labels=[\"<20\", \"20-29\", \"30-39\", \"40-49\", \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70+\"])\n",
    "\n",
    "filtered_data[\"HMLR LOS\"] = pd.cut(filtered_data[\"HMLR LOS (years)\"], bins=[0, 1, 3, 5, 10, 15, 20, 25, 30, 35, 40, 100], \n",
    "                                      labels=[\"<1\", \"1-3\", \"4-5\", \"6-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-35\", \"36-40\", \">40\"])\n",
    "\n",
    "filtered_data[\"CS LOS\"] = pd.cut(filtered_data[\"CS LOS (years)\"], bins=[0, 1, 3, 5, 10, 15, 20, 25, 30, 35, 40, 100], \n",
    "                                      labels=[\"<1\", \"1-3\", \"4-5\", \"6-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\", \"31-35\", \"36-40\", \">40\"])\n",
    "\n",
    "# Using countplot for displaying counts of each group:\n",
    "sns.countplot(x=\"Age_Group\", data=filtered_data, ax=axes[0])\n",
    "axes[0].set_title(\"Age Group Distribution - Retirements\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "sns.countplot(x=\"HMLR LOS\", data=filtered_data, ax=axes[1])\n",
    "axes[1].set_title(\"HMLR Length of Service Distribution - Retirements\")\n",
    "plt.xlabel(\"HMLR LOS\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "sns.countplot(x=\"CS LOS\", data=filtered_data, ax=axes[2])\n",
    "axes[2].set_title(\"Civil Service Length of Service Distribution - Retirements\")\n",
    "plt.xlabel(\"CS LOS\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "#sns.barplot(data=data_total_merge, x='CS LOS (years)', bins=10, ax=axes[2])\n",
    "#axes[2].set_title('Civil Service - Length of Service (years)')\n",
    "\n",
    "# Adjust layout and show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "# Creating counts and columns\n",
    "column5 = filtered_data['Pandemic']\n",
    "counts5 = filtered_data['Pandemic'].value_counts()\n",
    "\n",
    "column6 = filtered_data['Fulltime=1/Part-time=0']\n",
    "counts6 = filtered_data['Fulltime=1/Part-time=0'].value_counts()\n",
    "\n",
    "column7 = filtered_data['Person Gender']\n",
    "counts7 = filtered_data['Person Gender'].value_counts()\n",
    "\n",
    "column8 = filtered_data['Partial_Retirement']\n",
    "counts8 = filtered_data['Partial_Retirement'].value_counts()\n",
    "\n",
    "column9 = filtered_data['Leaving Reason']\n",
    "counts9 = filtered_data['Leaving Reason'].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(20, 15))\n",
    "\n",
    "# Create a bar plot for Location in the first subplot\n",
    "sns.countplot(x=column5, data=filtered_data, ax=axes[0])\n",
    "axes[0].set_title('Bar plot for Pandemic')\n",
    "\n",
    "sns.countplot(x=column9, data=filtered_data, ax=axes[1])\n",
    "axes[1].set_title('Bar plot for Leaving Reason')\n",
    "\n",
    "sns.countplot(x=column6, data=filtered_data, ax=axes[2])\n",
    "axes[2].set_title('Bar plot for Working Pattern')\n",
    "\n",
    "sns.countplot(x=column7, data=filtered_data, ax=axes[3])\n",
    "axes[3].set_title('Bar plot for Gender')\n",
    "\n",
    "sns.countplot(x=column8, data=filtered_data, ax=axes[4])\n",
    "axes[4].set_title('Bar plot for Partial Retirement')\n",
    "\n",
    "# Adjust layout and show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Need to calculate the numbers here to decide if this is imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aeeb92",
   "metadata": {},
   "source": [
    "### 2.5. Feature Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3386d",
   "metadata": {},
   "source": [
    "#### 2.5.1. Calculation of Bivariate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anova(df, feature, label):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    \n",
    "    groups = df[feature].unique()\n",
    "\n",
    "    data_grouped = df.groupby(feature)\n",
    "\n",
    "    group_labels = []\n",
    "    for g in groups:\n",
    "        g_list = data_grouped.get_group(g)\n",
    "        group_labels.append(g_list[label])\n",
    "        \n",
    "    return stats.f_oneway(*group_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivstats(df, label):\n",
    "    from scipy import stats\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Stat = r correlation, +/- = Anova, Effect Size = Chi Squared, p-value = p-value.\n",
    "        \n",
    "    corr_df = pd.DataFrame(columns=['Stat', '+/-', 'Effect size', 'p-value'])\n",
    "        \n",
    "    for col in df:\n",
    "        if not col == label:\n",
    "            if df[col].isnull().sum() == 0:\n",
    "            \n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    r,p = stats.pearsonr(df[label], df[col])\n",
    "                    corr_df.loc[col] = ['r', np.sign(r), abs(round(r, 3)), round(p, 6)] \n",
    "                else:\n",
    "                    F, p = Anova(df[[col, label]], col, label)\n",
    "                    corr_df.loc[col] = ['F', '', round(F, 3), round(p, 6)]\n",
    "            else:\n",
    "                corr_df.loc[col] = [np.nan, np.nan, np.nan, 'nulls']        \n",
    "                     \n",
    "    corr_df.sort_values(by=['Effect size'], ascending=False)\n",
    "    \n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "bivstats(data_total_merge, 'Age (years)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc342a",
   "metadata": {},
   "source": [
    "#### 2.5.2. Pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_total_merge, vars=['Age (years)', 'HMLR LOS (years)', 'CS LOS (years)', 'Partial_Retirement'])\n",
    "    \n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5feef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_total_merge, vars=['Age (years)', 'HMLR LOS (years)', 'CS LOS (years)','Partial_Retirement'],hue='Leaving Reason')    \n",
    "plt.savefig('visualisation1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_total_merge, vars=['Age (years)', 'HMLR LOS (years)', 'CS LOS (years)','Partial_Retirement'],hue='Person Gender')    \n",
    "plt.savefig('visualisation2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eca193",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_total_merge, vars=['Age (years)', 'HMLR LOS (years)', 'CS LOS (years)','Partial_Retirement'],hue='Pension Scheme')    \n",
    "plt.savefig('visualisation3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_total_merge, vars=['Age (years)', 'HMLR LOS (years)', 'CS LOS (years)','Partial_Retirement'],hue='Pandemic')    \n",
    "plt.savefig('visualisation4.png', dpi=300, bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42cb3b",
   "metadata": {},
   "source": [
    "#### 2.5.3. Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = filtered_data[['Age (years)','HMLR LOS (years)', 'CS LOS (years)', 'Partial_Retirement']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5aa805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Maybe some box plots to review outliers a little more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2bb4aa",
   "metadata": {},
   "source": [
    "## 3. Modelling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35617ff5",
   "metadata": {},
   "source": [
    "This section will look at final feature adaptions to prepare for the data to then be split for training and testing of the models that have been chosen to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98e6c3",
   "metadata": {},
   "source": [
    "### 3.1. Final feature changes\n",
    "\n",
    "After visualising the features it has shown some areas that will be best to adapt further to be binary results. These are the features that do not require any more detailed processing such as One Hot Encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7a30d",
   "metadata": {},
   "source": [
    "#### Person Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_total_merge['Person Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge.loc[(data_total_merge['Person Gender'] == 'Male'), 'Person Gender'] = 1 \n",
    "data_total_merge.loc[(data_total_merge['Person Gender'] == 'Female'), 'Person Gender'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8384cb9",
   "metadata": {},
   "source": [
    "#### Fulltime / Part-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7325ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_total_merge['Fulltime=1/Part-time=0'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb686d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge.loc[(data_total_merge['Fulltime=1/Part-time=0'] == 'Full time'), 'Fulltime=1/Part-time=0'] = 1 \n",
    "data_total_merge.loc[(data_total_merge['Fulltime=1/Part-time=0'] == 'Part time'), 'Fulltime=1/Part-time=0'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa0195",
   "metadata": {},
   "source": [
    "#### Leaving Reason\n",
    "\n",
    "The important question for this column is whether the 'Leaving Reason' is Retirement or not. Therefore I will amend the values to be a numerical binary view, Retirement = 1 and Non-Retirement = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4db5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_total_merge['Leaving Reason'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc99950",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge['Outcome'] = np.where(data_total_merge['Leaving Reason'] != 'Retirement', False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a136771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_merge.to_csv('final merge test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f2cc9",
   "metadata": {},
   "source": [
    "### 3.2. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_data = pd.get_dummies(data_total_merge, columns = ['Location','Grade','Directorate',\n",
    "                                                                   'Pension Scheme','Pandemic'])\n",
    "one_hot_encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing that the code has worked as I expected.\n",
    "one_hot_encoded_data.to_csv('Test Review Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corr = one_hot_encoded_data.corr()\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(full_corr, annot=False)\n",
    "plt.savefig('visualisation5.png', dpi=300, bbox_inches='tight')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5cb45",
   "metadata": {},
   "source": [
    "### 3.3. Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "cols_to_norm = ['Age (years)', 'CS LOS (years)','HMLR LOS (years)']\n",
    "one_hot_encoded_data[cols_to_norm] = scaler.fit_transform(one_hot_encoded_data[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c36c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing that the code has worked as I expected.\n",
    "\n",
    "one_hot_encoded_data.to_csv('Test Review Data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70f121",
   "metadata": {},
   "source": [
    "### 3.4. Training - Testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning the dataset to input & output\n",
    "\n",
    "x = one_hot_encoded_data[['Person Number','Fulltime=1/Part-time=0','Person Gender', \n",
    "                               'Partial_Retirement','Age (years)','CS LOS (years)','HMLR LOS (years)',\n",
    "                               'Location_Birkenhead','Location_Coventry', 'Location_Croydon', 'Location_Durham', \n",
    "                               'Location_Fylde','Location_Gloucester', 'Location_Hull', 'Location_Leicester', \n",
    "                               'Location_Nottingham','Location_Peterborough','Location_Plymouth','Location_Swansea', \n",
    "                               'Location_Telford','Location_Weymouth','Grade_AA','Grade_AO','Grade_APP','Grade_EO',\n",
    "                               'Grade_Grade 6','Grade_Grade 7','Grade_Grade 7 Lawyers','Grade_HEO','Grade_SCS1',\n",
    "                               'Grade_SCS2','Grade_SEO', 'Grade_SEO+', 'Directorate_CE & CLR', \n",
    "                               'Directorate_Customer & Strategy Group','Directorate_DDat',\n",
    "                               'Directorate_Data & Register Integrity Group', 'Directorate_FBS',\n",
    "                               'Directorate_Human Resources', 'Directorate_Independent Complaints Review', \n",
    "                               'Directorate_Operations', 'Directorate_Transformation', 'Pension Scheme_Alpha', \n",
    "                               'Pension Scheme_Classic', 'Pension Scheme_Classic Plus', 'Pension Scheme_L&G', \n",
    "                               'Pension Scheme_Nuvos', 'Pension Scheme_Premium', 'Pension Scheme_Unknown', \n",
    "                               'Pandemic_During-Pandemic', 'Pandemic_Post-Pandemic', 'Pandemic_Pre-Pandemic']]\n",
    "y = one_hot_encoded_data[['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134799ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdfa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv',index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv',index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01790b85",
   "metadata": {},
   "source": [
    "## 4. Classification Models\n",
    "\n",
    "This problem is a classification models and due to this and the research that I have completed I will be using the following algorithms to optimise, train & test:\n",
    "\n",
    "1. Random Forest (rf)\n",
    "2. Support Vector Classification (svc) / Support Vector Machines (svm)\n",
    "3. Logistic Regression (lg)\n",
    "4. K-Nearest Neighbours (knn)\n",
    "\n",
    "For each of these algorithms I will optimise the hyperparameters, complete a single run and then complete a multi run and calculate averages over a number of metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bedab0",
   "metadata": {},
   "source": [
    "### 4.1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61495d32",
   "metadata": {},
   "source": [
    "#### 4.1.1. Random Forest - First Run\n",
    "\n",
    "I will start by building the model and running this with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_predicted = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829959db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_predicted = rf_model.predict(X_test)\n",
    "\n",
    "rf_cm = confusion_matrix(y_test, rf_y_predicted)\n",
    "rf_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f385d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(rf_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6605c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, rf_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09576d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, rf_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_rf, rfc_tpr_rf, threshold_rf = roc_curve(y_test, rf_y_predicted)\n",
    "rf_auc_rfc = auc(rfc_fpr_rf, rfc_tpr_rf)\n",
    "\n",
    "print(\"AUC: \",rf_auc_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_rf, rfc_tpr_rf, linestyle='-', label='Random Forest (AUC = %0.3f)' % rf_auc_rfc)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba1202",
   "metadata": {},
   "source": [
    "#### 4.1.2. Random Forest - Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_start_time_training = time.time()\n",
    "\n",
    "param_grid_rf = [{\n",
    "    'n_estimators':[10,20,30,40,50,60,70,80,90,100,110,120,130,140,150],\n",
    "    'max_depth':[5,10,15,20],\n",
    "    'max_features':[2,3,4,5,6,7,8,9,10]},]\n",
    "\n",
    "rf_optimal_params = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=10, n_jobs=-1)\n",
    "\n",
    "rf_best_model = rf_optimal_params.fit(X_train, y_train)\n",
    "\n",
    "rf_end_time_training = time.time()\n",
    "\n",
    "print(rf_optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a380b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt_y_predicted = rf_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932018c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cm_opt = confusion_matrix(y_test, rf_opt_y_predicted)\n",
    "rf_cm_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(rf_cm_opt, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcb52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, rf_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e672521",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, rf_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_rf_opt, rfc_tpr_rf_opt, threshold_rf_opt = roc_curve(y_test, rf_opt_y_predicted)\n",
    "rf_opt_auc_rfc = auc(rfc_fpr_rf_opt, rfc_tpr_rf_opt)\n",
    "\n",
    "print(\"AUC: \",rf_opt_auc_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_rf_opt, rfc_tpr_rf_opt, linestyle='-', label='Random Forest (AUC = %0.3f)' % rf_opt_auc_rfc)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_training_time = rf_end_time_training - rf_start_time_training\n",
    "print(\"Training time:\", rf_training_time, \"seconds\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_multi = RandomForestClassifier(max_depth=5, max_features=9, n_estimators=30)\n",
    "rf_model_multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d180587",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_start_time_testing = time.time()\n",
    "\n",
    "rf_accuracy=[]\n",
    "rf_f1score=[]\n",
    "rf_roc=[]\n",
    "\n",
    "for i in range(100):    \n",
    "    rf_y_predicted_multi = rf_best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, rf_y_predicted_multi)\n",
    "    rf_accuracy.append(acc)\n",
    "    \n",
    "    f1 = f1_score(y_test, rf_y_predicted_multi)\n",
    "    rf_f1score.append(f1)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, rf_y_predicted_multi)\n",
    "    rf_roc.append(auc)\n",
    "    \n",
    "rf_end_time_testing = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_training_time = rf_end_time_training - rf_start_time_training\n",
    "print(\"Training time:\", rf_training_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "rf_testing_time = rf_end_time_testing - rf_start_time_testing\n",
    "print(\"Testing time:\", rf_testing_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "acc_average = statistics.mean(rf_accuracy)\n",
    "f1_average = statistics.mean(rf_f1score)\n",
    "roc_average = statistics.mean(rf_roc)\n",
    "\n",
    "print('This is the accuracy average', acc_average)\n",
    "print('This is the F1 average', f1_average)\n",
    "print('This is the AUC average', roc_average)\n",
    "print(\"\")\n",
    "\n",
    "acc_max = max(rf_accuracy)\n",
    "f1_max = max(rf_f1score)\n",
    "roc_max = max(rf_roc)\n",
    "\n",
    "print('This is the accuracy maximum', acc_max)\n",
    "print('This is the F1 maximum', f1_max)\n",
    "print('This is the AUC maximum', roc_max)\n",
    "print(\"\")\n",
    "\n",
    "acc_min = min(rf_accuracy)\n",
    "f1_min = min(rf_f1score)\n",
    "roc_min = min(rf_roc)\n",
    "\n",
    "print('This is the accuracy minimum', acc_min)\n",
    "print('This is the F1 minimum', f1_min)\n",
    "print('This is the AUC minimum', roc_min)\n",
    "print(\"\")\n",
    "\n",
    "acc_stdev = np.std(rf_accuracy)\n",
    "f1_stdev = np.std(rf_f1score)\n",
    "roc_stdev = np.std(rf_roc)\n",
    "\n",
    "print('This is the accuracy standard deviation', acc_stdev)\n",
    "print('This is the F1 standard deviation', f1_stdev)\n",
    "print('This is the AUC standard deviation', roc_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d16d7",
   "metadata": {},
   "source": [
    "### 4.2. Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7fff75",
   "metadata": {},
   "source": [
    "#### 4.2.1. SVM - First Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd99fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model = SVC()\n",
    "SVM_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc842818",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_y_predicted = SVM_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_cm = confusion_matrix(y_test, SVM_y_predicted)\n",
    "SVM_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ea141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(SVM_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1323890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, SVM_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, SVM_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912cc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_SVM, rfc_tpr_SVM, threshold_SVM = roc_curve(y_test, SVM_y_predicted)\n",
    "auc_rfc_SVM = auc(rfc_fpr_SVM, rfc_tpr_SVM)\n",
    "\n",
    "print('auc_rfc_SVM type:', type(auc_rfc_SVM))\n",
    "print(\"AUC: \", auc_rfc_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_SVM, rfc_tpr_SVM, linestyle='-', label='SVM (AUC = %0.3f)' % auc_rfc_SVM)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec99005",
   "metadata": {},
   "source": [
    "#### 4.2.2. SVM - Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8807c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_start_time_training = time.time()\n",
    "\n",
    "param_grid_SVM = [{\n",
    "    'C':[0.5, 1, 10, 100],\n",
    "    'gamma':[1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel':['rbf','linear']},]\n",
    "\n",
    "SVM_optimal_params = GridSearchCV(estimator=SVM_model, param_grid=param_grid_SVM, cv=10, n_jobs=-1)\n",
    "\n",
    "SVM_best_model = SVM_optimal_params.fit(X_train, y_train)\n",
    "\n",
    "SVM_end_time_training = time.time()\n",
    "\n",
    "print(SVM_optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_opt_y_predicted = SVM_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_opt_cm = confusion_matrix(y_test, SVM_opt_y_predicted)\n",
    "SVM_opt_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(SVM_opt_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab146ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, SVM_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, SVM_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0403e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_SVM_opt, rfc_tpr_SVM_opt, threshold_SVM_opt = roc_curve(y_test, SVM_opt_y_predicted)\n",
    "auc_rfc_SVM_opt = auc(rfc_fpr_SVM_opt, rfc_tpr_SVM_opt)\n",
    "\n",
    "print('AUC: ', auc_rfc_SVM_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fdf3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_SVM_opt, rfc_tpr_SVM_opt, linestyle='-', label='SVM - Optimised (AUC = %0.3f)' % auc_rfc_SVM_opt)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62965ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_training_time = SVM_end_time_training - SVM_start_time_training\n",
    "print(\"Training time:\", SVM_training_time, \"seconds\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model_multi = SVC(C=1, gamma=0.0001, kernel='rbf')\n",
    "SVM_model_multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0295fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_start_time_testing = time.time()\n",
    "\n",
    "SVM_accuracy=[]\n",
    "SVM_f1score=[]\n",
    "SVM_roc=[]\n",
    "\n",
    "for i in range(100):\n",
    "    SVM_y_predicted_multi = SVM_best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, SVM_y_predicted_multi)\n",
    "    SVM_accuracy.append(acc)\n",
    "    \n",
    "    f1 = f1_score(y_test, SVM_y_predicted_multi)\n",
    "    SVM_f1score.append(f1)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, SVM_y_predicted_multi)\n",
    "    SVM_roc.append(auc)\n",
    "    \n",
    "SVM_end_time_testing = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ddd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_training_time = SVM_end_time_training - SVM_start_time_training\n",
    "print(\"Training time:\", SVM_training_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "SVM_testing_time = SVM_end_time_testing - SVM_start_time_testing\n",
    "print(\"Testing time:\", SVM_testing_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "acc_average = statistics.mean(SVM_accuracy)\n",
    "f1_average = statistics.mean(SVM_f1score)\n",
    "roc_average = statistics.mean(SVM_roc)\n",
    "\n",
    "print('This is the accuracy average', acc_average)\n",
    "print('This is the F1 average', f1_average)\n",
    "print('This is the AUC average', roc_average)\n",
    "print(\"\")\n",
    "\n",
    "acc_max = max(SVM_accuracy)\n",
    "f1_max = max(SVM_f1score)\n",
    "roc_max = max(SVM_roc)\n",
    "\n",
    "print('This is the accuracy maximum', acc_max)\n",
    "print('This is the F1 maximum', f1_max)\n",
    "print('This is the AUC maximum', roc_max)\n",
    "print(\"\")\n",
    "\n",
    "acc_min = min(SVM_accuracy)\n",
    "f1_min = min(SVM_f1score)\n",
    "roc_min = min(SVM_roc)\n",
    "\n",
    "print('This is the accuracy minimum', acc_min)\n",
    "print('This is the F1 minimum', f1_min)\n",
    "print('This is the AUC minimum', roc_min)\n",
    "print(\"\")\n",
    "\n",
    "acc_stdev = np.std(SVM_accuracy)\n",
    "f1_stdev = np.std(SVM_f1score)\n",
    "roc_stdev = np.std(SVM_roc)\n",
    "\n",
    "print('This is the accuracy standard deviation', acc_stdev)\n",
    "print('This is the F1 standard deviation', f1_stdev)\n",
    "print('This is the AUC standard deviation', roc_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab7c0b",
   "metadata": {},
   "source": [
    "### 4.3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c38595",
   "metadata": {},
   "source": [
    "#### 4.3.1. Logistic Regression - First Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_y_predicted = lg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_cm = confusion_matrix(y_test, lg_y_predicted)\n",
    "lg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce89293",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(lg_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, lg_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, lg_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_lg, rfc_tpr_lg, threshold_lg = roc_curve(y_test, lg_y_predicted)\n",
    "auc_rfc_lg = auc(rfc_fpr_lg, rfc_tpr_lg)\n",
    "\n",
    "print('AUC: ', auc_rfc_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_lg, rfc_tpr_lg, linestyle='-', label='Logistic Regression (AUC = %0.3f)' % auc_rfc_lg)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf6b5e",
   "metadata": {},
   "source": [
    "#### 4.3.2. Logistic Regression - Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e790f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_start_time_training = time.time()\n",
    "\n",
    "param_grid_lg = [{\n",
    "    'C': np.logspace(-4,4,20),\n",
    "    'solver': ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter': [100,1000,2500,5000]},]\n",
    "\n",
    "\n",
    "lg_optimal_params = GridSearchCV(estimator=lg_model, param_grid= param_grid_lg, cv=10, n_jobs=-1)\n",
    "\n",
    "lg_best_model = lg_optimal_params.fit(X_train, y_train)\n",
    "\n",
    "lg_end_time_training = time.time()\n",
    "\n",
    "print(lg_optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_opt_y_predicted = lg_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c43578",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_opt_cm = confusion_matrix(y_test, lg_opt_y_predicted)\n",
    "lg_opt_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(lg_opt_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', accuracy_score(y_test, lg_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096738ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, lg_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f531cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_lg_opt, rfc_tpr_lg_opt, threshold_lg_opt = roc_curve(y_test, lg_opt_y_predicted)\n",
    "auc_rfc_lg_opt = auc(rfc_fpr_lg_opt, rfc_tpr_lg_opt)\n",
    "\n",
    "print('AUC: ', auc_rfc_lg_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d033c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_lg_opt, rfc_tpr_lg_opt, linestyle='-', label='Logistic Regression (AUC = %0.3f)' % auc_rfc_lg_opt)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_training_time = lg_end_time_training - lg_start_time_training\n",
    "print(\"Training time:\", lg_training_time, \"seconds\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#May not need the cell below!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a89685",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lg_start_time_training_1 = time.time()\n",
    "\n",
    "lg_accuracy = []\n",
    "lg_f1score = []\n",
    "lg_roc = []\n",
    "\n",
    "for i in range(100):\n",
    "    lg_multi = LogisticRegression()\n",
    "    \n",
    "    param_grid_lg = [{\n",
    "    'C': np.logspace(-4,4,20),\n",
    "    'solver': ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter': [100,1000,2500,5000]},]\n",
    "    \n",
    "    lg_optimal_params = GridSearchCV(estimator=lg_multi, param_grid= param_grid_lg, cv=10, n_jobs=-1)\n",
    "    lg_best_model = lg_optimal_params.fit(X_train, y_train)\n",
    "    \n",
    "    lg_y_predicted_multi = lg_best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, lg_y_predicted_multi)\n",
    "    lg_accuracy.append(acc)\n",
    "    \n",
    "    f1 = f1_score(y_test, lg_y_predicted_multi)\n",
    "    lg_f1score.append(f1)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, lg_y_predicted_multi)\n",
    "    lg_roc.append(auc)\n",
    "    \n",
    "lg_end_time_training_1 = time.time()\n",
    "\n",
    "print(lg_optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d572408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'C': 78.47599703514607, 'max_iter': 100, 'solver': 'newton-cg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_start_time_training = time.time()\n",
    "\n",
    "lg_model_multi = LogisticRegression(C= 78.47599703514607, max_iter= 100, solver= 'newton-cg')\n",
    "lg_model_multi.fit(X_test, y_test)\n",
    "\n",
    "lg_end_time_training = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_start_time_testing = time.time()\n",
    "\n",
    "lg_accuracy=[]\n",
    "lg_f1score=[]\n",
    "lg_roc=[]\n",
    "\n",
    "for i in range(100):    \n",
    "    lg_y_predicted_multi = lg_best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, lg_y_predicted_multi)\n",
    "    lg_accuracy.append(acc)\n",
    "    \n",
    "    f1 = f1_score(y_test, lg_y_predicted_multi)\n",
    "    lg_f1score.append(f1)\n",
    "    \n",
    "    rfc_fpr_lg, rfc_tpr_lg, threshold_lg = roc_curve(y_test, lg_y_predicted_multi)\n",
    "    auc_rfc_lg = auc(rfc_fpr_lg, rfc_tpr_lg)\n",
    "    lg_roc.append(auc_rfc_lg)\n",
    "    \n",
    "lg_end_time_testing = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad46f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_training_time = lg_end_time_training - lg_start_time_training\n",
    "print(\"Training time:\", lg_training_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "lg_testing_time = lg_end_time_testing - lg_start_time_testing\n",
    "print(\"Testing time:\", lg_testing_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "acc_average = statistics.mean(lg_accuracy)\n",
    "f1_average = statistics.mean(lg_f1score)\n",
    "roc_average = statistics.mean(lg_roc)\n",
    "\n",
    "print('This is the accuracy average', acc_average)\n",
    "print('This is the F1 average', f1_average)\n",
    "print('This is the AUC average', roc_average)\n",
    "print(\"\")\n",
    "\n",
    "acc_max = max(lg_accuracy)\n",
    "f1_max = max(lg_f1score)\n",
    "roc_max = max(lg_roc)\n",
    "\n",
    "print('This is the accuracy maximum', acc_max)\n",
    "print('This is the F1 maximum', f1_max)\n",
    "print('This is the AUC maximum', roc_max)\n",
    "print(\"\")\n",
    "\n",
    "acc_min = min(lg_accuracy)\n",
    "f1_min = min(lg_f1score)\n",
    "roc_min = min(lg_roc)\n",
    "\n",
    "print('This is the accuracy minimum', acc_min)\n",
    "print('This is the F1 minimum', f1_min)\n",
    "print('This is the AUC minimum', roc_min)\n",
    "print(\"\")\n",
    "\n",
    "acc_stdev = np.std(lg_accuracy)\n",
    "f1_stdev = np.std(lg_f1score)\n",
    "roc_stdev = np.std(lg_roc)\n",
    "\n",
    "print('This is the accuracy standard deviation', acc_stdev)\n",
    "print('This is the F1 standard deviation', f1_stdev)\n",
    "print('This is the AUC standard deviation', roc_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac45c6",
   "metadata": {},
   "source": [
    "### 4.4. K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8347b",
   "metadata": {},
   "source": [
    "#### 4.4.1. KNN - First Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbec641",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623334b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_y_predicted = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4125a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cm = confusion_matrix(y_test, knn_y_predicted)\n",
    "knn_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(knn_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, knn_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, knn_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_knn, rfc_tpr_knn, threshold_knn = roc_curve(y_test, knn_y_predicted)\n",
    "auc_rfc_knn = auc(rfc_fpr_knn, rfc_tpr_knn)\n",
    "\n",
    "print(auc_rfc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_knn, rfc_tpr_knn, linestyle='-', label='K-NN (AUC = %0.3f)' % auc_rfc_knn)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f2275",
   "metadata": {},
   "source": [
    "#### 4.4.2. KNN - Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimising the hyper parameters\n",
    "\n",
    "knn_start_time_training = time.time()\n",
    "\n",
    "param_grid_knn = [{\n",
    "        'n_neighbors': [1,2,3,4,5,6,7,8,9,10,20,30,40,50],\n",
    "            },]\n",
    "\n",
    "\n",
    "knn_optimal_params = GridSearchCV(estimator=knn, param_grid= param_grid_knn, cv=10, n_jobs=-1)\n",
    "\n",
    "knn_best_model = knn_optimal_params.fit(X_train, y_train)\n",
    "\n",
    "knn_end_time_training = time.time()\n",
    "\n",
    "print(knn_optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt_y_predicted = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt_cm = confusion_matrix(y_test, knn_opt_y_predicted)\n",
    "knn_opt_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(knn_opt_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcfc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, knn_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e591974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ', f1_score(y_test, knn_opt_y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_fpr_knn_opt, rfc_tpr_knn_opt, threshold_knn_opt = roc_curve(y_test, knn_opt_y_predicted)\n",
    "auc_rfc_knn_opt = auc(rfc_fpr_knn_opt, rfc_tpr_knn_opt)\n",
    "\n",
    "print(auc_rfc_knn_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(rfc_fpr_knn_opt, rfc_tpr_knn_opt, linestyle='-', label='K-NN (AUC = %0.3f)' % auc_rfc_knn_opt)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a934ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_training_time = knn_end_time_training - knn_start_time_training\n",
    "print(\"Training time:\", knn_training_time, \"seconds\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71388a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_start_time_training_1 = time.time()\n",
    "\n",
    "knn_accuracy = []\n",
    "knn_f1score = []\n",
    "knn_roc = []\n",
    "\n",
    "for i in range(100):\n",
    "    knn_multi = KNeighborsClassifier()\n",
    "    param_grid_knn = [{\n",
    "        'n_neighbors': [1,2,3,4,5,6,7,8,9,10,20,30,40,50],\n",
    "            },]\n",
    "    knn_optimal_params = GridSearchCV(estimator=knn_multi, param_grid= param_grid_knn, cv=10, n_jobs=-1)\n",
    "    knn_best_model = knn_optimal_params.fit(X_train, y_train)\n",
    "    knn_y_predicted_multi = knn_best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, knn_y_predicted_multi)\n",
    "    knn_accuracy.append(acc)\n",
    "    \n",
    "    f1 = f1_score(y_test, knn_y_predicted_multi)\n",
    "    knn_f1score.append(f1)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, knn_y_predicted_multi)\n",
    "    knn_roc.append(auc)\n",
    "    \n",
    "knn_end_time_training_1 = time.time()\n",
    "\n",
    "print(knn_optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dabe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_start_time_training = time.time()\n",
    "\n",
    "knn_multi = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_multi.fit(X_train, y_train)\n",
    "\n",
    "knn_end_time_training = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_start_time_testing = time.time()\n",
    "\n",
    "knn_accuracy=[]\n",
    "knn_f1score=[]\n",
    "knn_roc=[]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    knn_y_predicted_multi = knn_best_model.predict(X_test)\n",
    "   \n",
    "    acc = accuracy_score(y_test, knn_y_predicted_multi)\n",
    "    knn_accuracy.append(acc)\n",
    "   \n",
    "    f1 = f1_score(y_test, knn_y_predicted_multi)\n",
    "    knn_f1score.append(f1)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, knn_y_predicted_multi)\n",
    "    knn_roc.append(auc)\n",
    "    \n",
    "knn_end_time_testing = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_training_time_1 = knn_end_time_training_1 - knn_start_time_training_1\n",
    "print(\"Training time:\", knn_training_time_1, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "knn_testing_time = knn_end_time_testing - knn_start_time_testing\n",
    "print(\"Testing time:\", knn_testing_time, \"seconds\")\n",
    "print(\"\")\n",
    "\n",
    "acc_average = statistics.mean(knn_accuracy)\n",
    "f1_average = statistics.mean(knn_f1score)\n",
    "roc_average = statistics.mean(knn_roc)\n",
    "\n",
    "print('This is the accuracy average', acc_average)\n",
    "print('This is the F1 average', f1_average)\n",
    "print('This is the AUC average', roc_average)\n",
    "print(\"\")\n",
    "\n",
    "acc_max = max(knn_accuracy)\n",
    "f1_max = max(knn_f1score)\n",
    "roc_max = max(knn_roc)\n",
    "\n",
    "print('This is the accuracy maximum', acc_max)\n",
    "print('This is the F1 maximum', f1_max)\n",
    "print('This is the AUC maximum', roc_max)\n",
    "print(\"\")\n",
    "\n",
    "acc_min = min(knn_accuracy)\n",
    "f1_min = min(knn_f1score)\n",
    "roc_min = min(knn_roc)\n",
    "\n",
    "print('This is the accuracy minimum', acc_min)\n",
    "print('This is the F1 minimum', f1_min)\n",
    "print('This is the AUC minimum', roc_min)\n",
    "print(\"\")\n",
    "\n",
    "acc_stdev = np.std(knn_accuracy)\n",
    "f1_stdev = np.std(knn_f1score)\n",
    "roc_stdev = np.std(knn_roc)\n",
    "\n",
    "print('This is the accuracy standard deviation', acc_stdev)\n",
    "print('This is the F1 standard deviation', f1_stdev)\n",
    "print('This is the AUC standard deviation', roc_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b003f",
   "metadata": {},
   "source": [
    "# NOTES: Try to run just the predict section through the iterative process, rather than the training and testing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c63c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## At end of section 2\n",
    "# maybe some more deep statistical testing\n",
    "# talk about normality, heterostacity\n",
    "\n",
    "\n",
    "# 5. Reviewing Outputs to select the model to move forward with.\n",
    "# 5.1 Code to present results\n",
    "# 5.2. Select the model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
